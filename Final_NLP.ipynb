{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6124f412-0e17-4f6f-8d04-e510817b4165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS === #\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as VaderAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === LOAD ENVIRONMENT VARIABLES === #\n",
    "load_dotenv()\n",
    "api_key = os.getenv('NEWS_API_KEY')\n",
    "\n",
    "# === SET UP NEWS API CALL === #\n",
    "url = 'https://newsapi.org/v2/everything'\n",
    "parameters = {\n",
    "    'q': 'NVDA',  # Use stock ticker of interest\n",
    "    'apiKey': api_key,\n",
    "    'language': 'en',\n",
    "    'pageSize': 15\n",
    "}\n",
    "\n",
    "# === MAKE NEWS API REQUEST === #\n",
    "response = requests.get(url, params=parameters)\n",
    "if response.status_code != 200:\n",
    "    print(\"Failed to retrieve news:\", response.status_code)\n",
    "    exit()\n",
    "\n",
    "# === PARSE NEWS ARTICLES === #\n",
    "data = response.json()\n",
    "news_df = pd.DataFrame(data['articles'])\n",
    "news_df['publishedAt'] = pd.to_datetime(news_df['publishedAt']).dt.date\n",
    "\n",
    "# === SETUP NLP TOOLS === #\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# === TEXT CLEANING FUNCTION === #\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return \" \".join([word for word in word_tokenize(text) if word not in stop_words])\n",
    "\n",
    "# === CLEAN TITLES AND APPLY VADER SENTIMENT === #\n",
    "news_df['cleaned_title'] = news_df['title'].apply(clean_text)\n",
    "news_df['sentiment'] = news_df['cleaned_title'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "\n",
    "# === LOAD FINANCIAL SENTIMENT DICTIONARY === #\n",
    "lm_df = pd.read_csv(r'C:\\Users\\roman\\Downloads\\Loughran-McDonald_MasterDictionary_1993-2023.csv')\n",
    "lm_positive = set(lm_df[lm_df['Positive'] > 0]['Word'].str.lower())\n",
    "lm_negative = set(lm_df[lm_df['Negative'] > 0]['Word'].str.lower())\n",
    "\n",
    "# === ADJUST SENTIMENT BASED ON FINANCIAL CONTEXT === #\n",
    "def financial_sentiment_adjustment(text, sentiment_score):\n",
    "    words = text.lower().split()\n",
    "    pos_score, neg_score = 0, 0\n",
    "    for word in words:\n",
    "        if word in lm_positive:\n",
    "            pos_score += 1\n",
    "        elif word in lm_negative:\n",
    "            neg_score += 1\n",
    "    adjusted = sentiment_score + (pos_score - neg_score) * 0.1\n",
    "    return max(-1, min(1, adjusted))\n",
    "\n",
    "news_df['adjusted_sentiment'] = news_df.apply(\n",
    "    lambda row: financial_sentiment_adjustment(row['cleaned_title'], row['sentiment']), axis=1)\n",
    "\n",
    "# === AGGREGATE SENTIMENT BY DATE === #\n",
    "daily_adjusted_sentiment = news_df.groupby('publishedAt')['adjusted_sentiment'].mean().reset_index()\n",
    "\n",
    "# === LOAD STOCK DATA === #\n",
    "stock_data = yf.download('NVDA', start='2025-01-01', end='2025-02-01')\n",
    "stock_data = stock_data[['Close']].reset_index()\n",
    "stock_data['Date'] = pd.to_datetime(stock_data['Date'])\n",
    "\n",
    "# === MERGE NEWS WITH STOCK DATA === #\n",
    "news_df['publishedAt'] = pd.to_datetime(news_df['publishedAt'])\n",
    "merged_data = pd.merge(news_df, stock_data, left_on='publishedAt', right_on='Date', how='inner')\n",
    "\n",
    "# === FEATURE ENGINEERING === #\n",
    "merged_data.set_index(pd.to_datetime(merged_data['publishedAt']), inplace=True)\n",
    "merged_data['lagged_sentiment'] = merged_data['adjusted_sentiment'].shift(1)\n",
    "merged_data['7_day_MA'] = merged_data['Close'].rolling(window=7).mean()\n",
    "merged_data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# === NORMALIZE FEATURES === #\n",
    "scaler = StandardScaler()\n",
    "merged_data[['adjusted_sentiment', 'Close', '7_day_MA']] = scaler.fit_transform(\n",
    "    merged_data[['adjusted_sentiment', 'Close', '7_day_MA']]\n",
    ")\n",
    "\n",
    "# === MODEL TRAINING - RIDGE REGRESSION === #\n",
    "X = merged_data[['adjusted_sentiment', 'Close', '7_day_MA']]\n",
    "y = merged_data['Close']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "y_train_imputed = y_train.values.reshape(-1, 1)\n",
    "y_test_imputed = y_test.values.reshape(-1, 1)\n",
    "\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train_imputed, y_train_imputed)\n",
    "\n",
    "ridge_r_squared = ridge_model.score(X_test_imputed, y_test_imputed)\n",
    "print(\"Ridge R-squared:\", ridge_r_squared)\n",
    "\n",
    "cv_scores = cross_val_score(ridge_model, X_train_imputed, y_train_imputed.ravel(), cv=5)\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Average Cross-Validation Score:\", np.mean(cv_scores))\n",
    "\n",
    "# === FEATURE SELECTION === #\n",
    "feature_selector = RFE(ridge_model, n_features_to_select=1)\n",
    "feature_selector.fit(X_train_imputed, y_train_imputed.ravel())\n",
    "selected_features = X.columns[feature_selector.support_]\n",
    "print(\"Selected Features by RFE:\", selected_features)\n",
    "\n",
    "# === FINAL MODEL === #\n",
    "final_model = Ridge(alpha=1.0)\n",
    "final_model.fit(X_train_imputed[:, feature_selector.support_], y_train_imputed)\n",
    "final_r_squared = final_model.score(X_test_imputed[:, feature_selector.support_], y_test_imputed)\n",
    "print(\"Final R-squared with selected features:\", final_r_squared)\n",
    "\n",
    "# === HOURLY MOVEMENT PREDICTION (LOGISTIC REGRESSION) === #\n",
    "merged_data_hourly = merged_data.resample('H').mean().fillna(method='ffill')\n",
    "merged_data_hourly['Movement'] = (merged_data_hourly['Close'].shift(-1) > merged_data_hourly['Close']).astype(int)\n",
    "merged_data_hourly['lagged_sentiment'] = merged_data_hourly['adjusted_sentiment'].shift(1)\n",
    "merged_data_hourly.dropna(inplace=True)\n",
    "\n",
    "X_hourly = merged_data_hourly[['adjusted_sentiment', '7_day_MA', 'lagged_sentiment']]\n",
    "y_hourly = merged_data_hourly['Movement']\n",
    "split_index = int(len(X_hourly) * 0.8)\n",
    "X_train_hourly, X_test_hourly = X_hourly.iloc[:split_index], X_hourly.iloc[split_index:]\n",
    "y_train_hourly, y_test_hourly = y_hourly.iloc[:split_index], y_hourly.iloc[split_index:]\n",
    "\n",
    "X_train_hourly_imputed = imputer.fit_transform(X_train_hourly)\n",
    "X_test_hourly_imputed = imputer.transform(X_test_hourly)\n",
    "\n",
    "model_lr_hourly = LogisticRegression()\n",
    "model_lr_hourly.fit(X_train_hourly_imputed, y_train_hourly)\n",
    "y_pred_lr_hourly = model_lr_hourly.predict(X_test_hourly_imputed)\n",
    "\n",
    "print(\"Hourly Logistic Regression Accuracy:\", accuracy_score(y_test_hourly, y_pred_lr_hourly))\n",
    "print(\"Hourly Classification Report:\\n\", classification_report(y_test_hourly, y_pred_lr_hourly))\n",
    "\n",
    "# === VISUALIZATION: PREDICTED VS ACTUAL PRICES === #\n",
    "ridge_predictions = ridge_model.predict(X_test_imputed)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test_imputed, label='Actual Stock Price', color='blue', alpha=0.7)\n",
    "plt.plot(ridge_predictions, label='Predicted Stock Price', color='red', alpha=0.7)\n",
    "plt.title('Ridge Regression: Actual vs Predicted Stock Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
